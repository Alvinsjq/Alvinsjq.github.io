<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="apple-mobile-web-app-capable" content="yes"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title> Implement a naive Bayes classifier for spam classification | Alvin Is </title> <!-- Icons --> <link rel="apple-touch-icon" type=" image/png" sizes="144x144" href="assets/images/webicon.png"> <link rel="icon" type=" image/png" href="/assets/images/webicon_32.png"> <link rel="shortcut icon" type=" image/png" href="/assets/images/webicon_32.png"> <meta name="description" content=" 这是cs229的homework中的一道题，用朴素贝叶斯算法实现垃圾邮件的分类，并且使用多项事件模型和拉普拉斯平滑。 "> <meta name="keywords" content=""> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <!-- Social: Facebook / Open Graph --> <meta property="og:type" content="article"> <meta property="article:author" content="Alvinsjq"> <meta property="article:section" content="机器学习"> <meta property="article:tag" content=""> <meta property="article:published_time" content="2017-07-22 00:38:22 +0800"> <meta property="og:url" content="http://alvinsjq.github.io/2017/a-case-of-naive-bayes/"> <meta property="og:title" content=" Implement a naive Bayes classifier for spam classification | Alvin Is "> <meta property="og:image" content="http://alvinsjq.github.io"> <meta property="og:description" content=" 这是cs229的homework中的一道题，用朴素贝叶斯算法实现垃圾邮件的分类，并且使用多项事件模型和拉普拉斯平滑。 "> <meta property="og:site_name" content="Alvinsjq"> <meta property="og:locale" content="en_US"> <!-- Social: Twitter --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:site" content="@Alvin_sjq"> <meta name="twitter:title" content=" Implement a naive Bayes classifier for spam classification | Alvin Is "> <meta name="twitter:description" content=" 这是cs229的homework中的一道题，用朴素贝叶斯算法实现垃圾邮件的分类，并且使用多项事件模型和拉普拉斯平滑。 "> <meta name="twitter:image:src" content="http://alvinsjq.github.io"> <!-- Social: Google+ / Schema.org --> <meta itemprop="name" content=" Implement a naive Bayes classifier for spam classification | Alvin Is "> <meta itemprop="description" content=" 这是cs229的homework中的一道题，用朴素贝叶斯算法实现垃圾邮件的分类，并且使用多项事件模型和拉普拉斯平滑。 "> <meta itemprop="image" content="http://alvinsjq.github.io"> <!-- rel prev and next --> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="stylesheet" href="/assets/css/font-awesome.min.css"> <!-- Canonical link tag --> <link rel="canonical" href="http://alvinsjq.github.io/2017/a-case-of-naive-bayes/"> <link rel="alternate" type="application/rss+xml" title="Alvin Is" href="http://alvinsjq.github.io/feed.xml"> <script type="text/javascript"> var disqus_shortname = 'alvin-is'; var _gaq = _gaq || []; _gaq.push(['_setAccount', '']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); </script> <script src="https://code.jquery.com/jquery-3.2.0.min.js"></script> <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script> <script>AV.initialize("OfIL1RlM4M4n30dWx3wXlEIz-gzGzoHsz", "LlDtB3Xu9be1655lnGQdPedO");</script> <script> function showHitCount(Counter) { var query = new AV.Query(Counter); var entries = []; var $visitors = $(".leancloud_visitors"); $visitors.each(function () { entries.push( $(this).attr("id").trim() ); }); query.containedIn('url', entries); query.find() .done(function (results) { var COUNT_CONTAINER_REF = '.leancloud-visitors-count'; if (results.length === 0) { $visitors.find(COUNT_CONTAINER_REF).text(0); return; } for (var i = 0; i < results.length; i++) { var item = results[i]; var url = item.get('url'); var hits = item.get('hits'); var element = document.getElementById(url); $(element).find(COUNT_CONTAINER_REF).text(hits); } for(var i = 0; i < entries.length; i++) { var url = entries[i]; var element = document.getElementById(url); var countSpan = $(element).find(COUNT_CONTAINER_REF); if( countSpan.text() == '') { countSpan.text(0); } } }) .fail(function (object, error) { console.log("Error: " + error.code + " " + error.message); }); } function addCount(Counter) { var $visitors = $(".leancloud_visitors"); var url = $visitors.attr('id').trim(); var title = $visitors.attr('data-flag-title').trim(); var query = new AV.Query(Counter); query.equalTo("url", url); query.find({ success: function(results) { if (results.length > 0) { var counter = results[0]; counter.fetchWhenSave(true); counter.increment("hits"); counter.save(null, { success: function(counter) { var $element = $(document.getElementById(url)); $element.find('.leancloud-visitors-count').text(counter.get('hits')); }, error: function(counter, error) { console.log('Failed to save Visitor num, with error message: ' + error.message); } }); } else { var newcounter = new Counter(); var acl = new AV.ACL(); acl.setPublicReadAccess(true); acl.setPublicWriteAccess(true); newcounter.setACL(acl); newcounter.set("title", title); newcounter.set("url", url); newcounter.set("hits", 1); newcounter.save(null, { success: function(newcounter) { var $element = $(document.getElementById(url)); $element.find('.leancloud-visitors-count').text(newcounter.get('hits')); }, error: function(newcounter, error) { console.log('Failed to create'); } }); } }, error: function(error) { console.log('Error:' + error.code + " " + error.message); } }); } $(function() { var Counter = AV.Object.extend("Counter"); if ($('.leancloud_visitors').length == 1) { addCount(Counter); } else if ($('.post-link').length > 1){ showHitCount(Counter); } }); </script> <script> var _hmt = _hmt || []; (function() { var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?011d93aa32b263cf21d7c9a15165b8a0"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); })(); </script> </head> <body> <main class="wrapper"> <header class="site-header"> <nav class="nav"> <div class="container"> <h1 class="logo"><a href="/">Alvin Is<span></span></a></h1> <ul class="navbar"> <li><a href="/about">About</a></li> <li><a href="/talks">Topics</a></li> <li><a href="/archives">Archives</a></li> <li><a href="/feed.xml" target="_blank"></a></li> </ul> </div> </nav> </header> <article class="post container" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <p class="post-meta"><time datetime="2017-07-22T00:38:22+08:00" itemprop="datePublished">Jul 22, 2017</time> <span id="/2017/a-case-of-naive-bayes/" class="leancloud_visitors" data-flag-title="Implement a naive Bayes classifier for spam classification"> <span class="post-meta-divider">|</span> <span class="post-meta-item-text"> 浏览次数: </span> <span class="leancloud-visitors-count"></span> </span> </p> <h1 class="post-title" itemprop="name headline">Implement a naive Bayes classifier for spam classification</h1> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> </header> <div class="post-content" itemprop="articleBody"> <p>这是一道来自CS 229, Autumn 2016 Problem Set #2 的作业题，根据给定的数据，使用朴素贝叶斯算法来对垃圾邮件进行分类。</p> <h4 id="section">概述</h4> <p>垃圾邮件分类中的特征向量一般都是离散值，根据lecture note上对垃圾邮件过滤器的讲述，我们知道特征向量x可以用来表示一封邮件，$ x=[x_{1},…,x_{n}]^{T}$中$x_{i}=1$就代表这封邮件包含在词汇集中的第i个字符。类似地，在这道习题中，也会有一个已经处理好的词汇集，列出了邮件中会出现的单词，但是这里面只存了一些出现频率为中等的词汇，因为偶尔出现和频繁出现的（例如of，the这类的）词汇分类的价值有限。当然还预先使用了一些调控算法使得形近的单词转为一样的词，例如“price”，“prices”，“priced”都看作是“price“。那么该题提供的词汇集有1448个单词。</p> <h4 id="section-1">朴素贝叶斯思想</h4> <p><strong>条件独立</strong></p> <p>朴素贝叶斯用到的假设就是条件独立假设：</p> <blockquote> <p><strong>Definition</strong>: Given three sets of random variables X,Y and Z, we say X is <strong>conditionally independent</strong> of Y given Z, if and only if the probability distribution governing X is independent of the value of Y given Z; that is:</p> </blockquote> <script type="math/tex; mode=display">(\forall i,j,k) P(X=x_{i}|Y=y_{j},Z=z_{k})=P(X=x_{i}|Z=z_{k})</script> <p>因此我们就可以将概率写成：</p> <script type="math/tex; mode=display">P(X_{1},...,X_{n}|Y) = \prod_{i=1}^{n} P(X_{i}|Y)</script> <!--more--> <p><strong>参数</strong></p> <p>正如讲义与作业中设定的，我们设一些参数：</p> <script type="math/tex; mode=display">\phi_{i| y=1} = p(x_{i}=1|\ y=1)</script> <script type="math/tex; mode=display">\phi_{i| y=0} = p(x_{i}=1|\ y=0)</script> <script type="math/tex; mode=display">\phi_{i| y=1} = p(y=1)</script> <p>由于似然概率</p> <script type="math/tex; mode=display">L(\phi_{i| y=1},\phi_{i| y=0}, \phi_{i| y=1}) = \prod_{i=1}^{m} p(x^{(i)},y^{(i)})</script> <p>因此取对数并求偏导设为零可求得参数值</p> <script type="math/tex; mode=display">\phi_{j|y=1} = \frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1 \land y^{(i)}=1 \}}{ \sum_{i=1}^{m} 1 \{ y^{(i)}=1\}}</script> <script type="math/tex; mode=display">\phi_{j|y=0} = \frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1 \land y^{(i)}=0 \}}{ \sum_{i=1}^{m} 1 \{ y^{(i)}=0\}}</script> <script type="math/tex; mode=display">\phi_{y} = \frac{\sum_{i=1}^{m} 1 \{ y^{(i)}=1\}}{m}</script> <p><strong>测试</strong></p> <p>那么这样给定一个测试向量$X^{new}$，那么通过上面的参数我们就可以进行预测：</p> <script type="math/tex; mode=display">Y^{new} = arg\ max_{y} \frac{p(y)\prod_{i}p(x_{i}|y)}{p(y=0)\prod_{i}p(x_{i}|y=0)+p(y=1)\prod_{i}p(x_{i}|y=1)}</script> <h4 id="section-2">优化——拉普拉斯平滑</h4> <p>为防止概率事件为0，则需要加上一些平滑参数，从而得到该题下新的参数估计：</p> <script type="math/tex; mode=display">\phi_{j|y=1} = \frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1 \land y^{(i)}=1 \}+1}{ \sum_{i=1}^{m} 1 \{ y^{(i)}=1\}+2}</script> <script type="math/tex; mode=display">\phi_{j|y=0} = \frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1 \land y^{(i)}=0 \}+1}{ \sum_{i=1}^{m} 1 \{ y^{(i)}=0\}+2}</script> <script type="math/tex; mode=display">\phi_{y} = \frac{\sum_{i=1}^{m} 1 \{ y^{(i)}=1\}+1}{m+2}</script> <h4 id="section-3">垃圾邮件分类</h4> <p><strong>预处理</strong></p> <p>习题给出了一些必要的调用函数，其中readMatrix函数对训练数据进行了预处理，从而得到spmatrix, tokenlist, trainCategory。</p> <ul> <li>spmatrix<br /> readMatrix先得到一个稀疏矩阵matrix，用sparse实现，</li> </ul> <div class="highlighter-rouge"><pre class="highlight"><code>...
(39,1033)     2
(10,1035)     1
(31,1035)     1
(18,1036)     4
(38,1036)     2
(2,1037)      1
...
</code></pre></div> <p>该矩阵的行代表一个样例，列代表不同的的词汇token，而矩阵(i,j)元素则是在邮件i中第j个token出现的数量；</p> <ul> <li> <p>tokenlist<br /> 这个就是词汇token向量；</p> </li> <li> <p>trainCategory<br /> trainCategory也是一个向量。</p> </li> </ul> <p><strong>训练函数nb_train.m</strong></p> <p>下面是朴素贝叶斯的训练算法，这里的trainMatrix将矩阵spmatrix转换为稀疏矩阵。</p> <div class="highlighter-rouge"><pre class="highlight"><code><span class="p">[</span><span class="n">spmatrix</span><span class="p">,</span> <span class="n">tokenlist</span><span class="p">,</span> <span class="n">trainCategory</span><span class="p">]</span> <span class="o">=</span> <span class="n">readMatrix</span><span class="p">(</span><span class="err">'</span><span class="n">MATRIX</span><span class="p">.</span><span class="n">TRAIN</span><span class="err">'</span><span class="p">);</span>

<span class="n">trainMatrix</span> <span class="o">=</span> <span class="n">full</span><span class="p">(</span><span class="n">spmatrix</span><span class="p">);</span>
<span class="n">numTrainDocs</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span> <span class="o">%</span> <span class="n">trainMatrix</span><span class="err">矩阵的行数</span>
<span class="n">numTokens</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>    <span class="o">%</span> <span class="n">trainMatrix</span><span class="err">矩阵的列数</span>  

<span class="o">%</span> <span class="n">YOUR</span> <span class="n">CODE</span> <span class="n">HERE</span>

     <span class="n">V</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span> <span class="o">%</span> <span class="n">trainMatrix</span><span class="err">矩阵的列数，特征向量</span><span class="n">X</span><span class="err">的维数</span>
     <span class="n">neg</span> <span class="o">=</span> <span class="n">trainMatrix</span><span class="p">(</span><span class="n">find</span><span class="p">(</span><span class="n">trainCategory</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="o">:</span><span class="p">);</span> <span class="o">%</span> <span class="n">neg</span><span class="err">矩阵表示的是那些标签为</span><span class="mi">0</span><span class="err">的样本</span>
     <span class="n">pos</span> <span class="o">=</span> <span class="n">trainMatrix</span><span class="p">(</span><span class="n">find</span><span class="p">(</span><span class="n">trainCategory</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="o">:</span><span class="p">);</span> <span class="o">%</span> <span class="n">neg</span><span class="err">矩阵表示的是那些标签为</span><span class="mi">1</span><span class="err">的样本</span>
     <span class="n">neg_words</span> <span class="o">=</span> <span class="n">sum</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">neg</span><span class="p">));</span> <span class="o">%</span> <span class="err">存储</span><span class="n">neg</span><span class="err">矩阵的元素之和</span>
     <span class="n">pos_words</span> <span class="o">=</span> <span class="n">sum</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">pos</span><span class="p">));</span> <span class="o">%</span> <span class="err">存储</span><span class="n">pos</span><span class="err">矩阵的元素之和</span>
     <span class="n">neg_log_prior</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">numTrainDocs</span><span class="p">);</span>  <span class="o">%</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="err">的先验概率</span>
     <span class="n">pos_log_prior</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">numTrainDocs</span><span class="p">);</span>  <span class="o">%</span> <span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="err">的先验概率</span>

     <span class="k">for</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">V</span><span class="p">,</span>  <span class="o">%</span> <span class="err">对特征向量的每一个</span><span class="n">token</span><span class="err">计算它们的</span><span class="n">log</span><span class="err">先验概率，</span>
       <span class="n">neg_log_phi</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">=</span> <span class="n">log</span><span class="p">((</span><span class="n">sum</span><span class="p">(</span><span class="n">neg</span><span class="p">(</span><span class="o">:</span><span class="p">,</span><span class="n">k</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">neg_words</span> <span class="o">+</span> <span class="n">V</span><span class="p">));</span>  <span class="o">%</span> <span class="err">对应公式</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span><span class="err">，注意这里的</span><span class="n">token</span><span class="err">计算的是出现的个数</span>
       <span class="n">pos_log_phi</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">=</span> <span class="n">log</span><span class="p">((</span><span class="n">sum</span><span class="p">(</span><span class="n">pos</span><span class="p">(</span><span class="o">:</span><span class="p">,</span><span class="n">k</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">pos_words</span> <span class="o">+</span> <span class="n">V</span><span class="p">));</span>  <span class="o">%</span> <span class="err">对应公式</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span> 
<span class="n">end</span>
</code></pre></div> <p><strong>测试函数nb_test.m</strong></p> <div class="highlighter-rouge"><pre class="highlight"><code><span class="k">for</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">numTestDocs</span><span class="p">,</span>
       <span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">find</span><span class="p">(</span><span class="n">testMatrix</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="o">:</span><span class="p">));</span> 
       <span class="o">%</span> <span class="err">得到第</span><span class="n">k</span><span class="err">个测试样本</span> 
       <span class="o">%</span> <span class="n">i</span><span class="err">向量则是非零元素所在的行，这种情况下都是</span><span class="mi">1</span>
       <span class="o">%</span> <span class="n">j</span><span class="err">向量则是非零元素所在的列，这就意味着可以知道有哪些</span><span class="n">token</span><span class="err">的个数非零</span> 
       <span class="o">%</span> <span class="n">v</span><span class="err">向量则是非零元素的值</span>

       <span class="o">%</span> <span class="err">计算后验概率，由于是取</span><span class="n">log</span><span class="err">，因此这里有‘</span><span class="o">+</span><span class="err">’</span>
       <span class="n">neg_posterior</span> <span class="o">=</span> <span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="p">.</span><span class="o">*</span> <span class="n">neg_log_phi</span><span class="p">(</span><span class="n">j</span><span class="p">))</span> <span class="o">+</span> <span class="n">neg_log_prior</span><span class="p">;</span> 
       <span class="n">pos_posterior</span> <span class="o">=</span> <span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="p">.</span><span class="o">*</span> <span class="n">pos_log_phi</span><span class="p">(</span><span class="n">j</span><span class="p">))</span> <span class="o">+</span> <span class="n">pos_log_prior</span><span class="p">;</span>

       <span class="k">if</span> <span class="p">(</span><span class="n">neg_posterior</span> <span class="o">&gt;</span> <span class="n">pos_posterior</span><span class="p">)</span>
         <span class="n">output</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
       <span class="k">else</span>
         <span class="n">output</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
       <span class="n">end</span>
<span class="n">end</span>
</code></pre></div> <p>最后如果对所有训练集都进行训练的话，可以得到测试误差为1.63%。</p> <blockquote> <p>该博文为学习机器学习时的笔记，由于水平有限，可能会存在错误，欢迎指正。</p> </blockquote> <aside class="share"> <p>If you liked this article and think others should read it, please share it on <a href="http://twitter.com/share?text=Implement a naive Bayes classifier for spam classification&amp;url=http://alvinsjq.github.io/2017/a-case-of-naive-bayes/&amp;via=Alvin_sjq" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">Twitter <i class="fa fa-twitter" aria-hidden="true" style="color:#00aced"></i></a>or <a href="https://www.facebook.com/sharer/sharer.php?u=http://alvinsjq.github.io/2017/a-case-of-naive-bayes/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=235');return false;">facebook <i class="fa fa-facebook-square" aria-hidden="true" style="color:#3b5998"></i></a>.</p> </aside> </div> <style type="text/css"> .tagged { margin-top: 1rem; } .tagged a { border: 1px solid #ddd; padding: 2px 5px; background: transparent; display: inline-block; color: #999; outline: 0; text-decoration: none; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; font-size: 70%; } .tagged a:hover { cursor: pointer; border: 1px solid #555; background: #444; color: #fff; } .back { /*text-align: center;*/ text-transform: uppercase; letter-spacing: 1px; } </style> <div class="tagged"> <a href="http://alvinsjq.github.io/tagged#机器学习"><i class="fa fa-hashtag" aria-hidden="true"></i>机器学习</a> <a href="http://alvinsjq.github.io/tagged#cs229"><i class="fa fa-hashtag" aria-hidden="true"></i>cs229</a> </div> <br> <div class="back"><a href="/"><i class="fa fa-chevron-left"></i>Back</a></div> </article> <aside id="comments" class="disqus"> <div class="container"> <div id="gitmentContainer"></div> <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"> <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script> <script> var gitment = new Gitment({ id: '<%= page.title %>', owner: 'Alvinsjq', repo: 'Alvinsjq.github.io', oauth: { client_id: 'b108345cd65235055f4a', client_secret: '2faaebf58d2e33a50a022d84c6448d9d9535feda', }, }); gitment.render('gitmentContainer'); </script> </div> </aside> <footer class="site-footer"> <div class="container"> <small class="block">&copy; 2018 Alvinsjq. All rights reserved.</small> <small><a href="https://github.com/heiswayi/thinkspace">Thanks for <i class="fa fa-heart" aria-hidden="true" style="color:#DD3D36"></i> Thinkspace</a> theme by <a href="http://heiswayi.github.io/">Heiswayi Nrird</a>.</small> <div class="footer-social-links"> <a href="http://alvinsjq.github.io/feed.xml" title="RSS Feed" target="_blank"><i class="fa fa-rss"></i></a> <a href="http://weibo.com/p/1005051719812480/home" title="Weibo" target="_blank"><i class="fa fa-weibo" aria-hidden="true"></i></a> <a href="https://twitter.com/Alvin_sjq" title="Twitter" target="_blank"><i class="fa fa-twitter"></i></a> <a href="https://github.com/Alvinsjq/" title="GitHub Repositories" target="_blank"><i class="fa fa-github-alt"></i></a> <a href="https://www.instagram.com/sj_alvin/" title="Instagram" target="_blank"><i class="fa fa-instagram"></i></a> </div> </div> </footer> </main> </body> </html>
